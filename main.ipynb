{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6348fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "278f6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('img.jpeg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aac0d603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[197, 197, 197, ..., 203, 203, 203],\n",
       "       [197, 197, 197, ..., 203, 203, 203],\n",
       "       [197, 197, 197, ..., 203, 203, 203],\n",
       "       ...,\n",
       "       [ 58,  53,  47, ...,  65,  65,  63],\n",
       "       [ 58,  53,  47, ...,  65,  65,  63],\n",
       "       [ 58,  53,  47, ...,  65,  65,  63]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_picture = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)#make picture gray\n",
    "gray_picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551c8f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42, 54, 92, 92]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces = face_cascade.detectMultiScale(gray_picture, 1.3, 5)\n",
    "\n",
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64addd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "244b480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('my image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7733299",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_face = gray_picture[y:y+h, x:x+w] # cut the gray face frame out\n",
    "face = img[y:y+h, x:x+w] # cut the face frame out\n",
    "eyes = eye_cascade.detectMultiScale(gray_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9696f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (ex,ey,ew,eh) in eyes: \n",
    "    cv2.rectangle(face,(ex,ey),(ex+ew,ey+eh),(0,225,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cc290fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('my image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "222cb1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_eyes(img, classifier):\n",
    "    gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    eyes = eyecenter.detectMultiScale(gray_frame, 1.3, 5) # detect eyes\n",
    "    width = np.size(img, 1) # get face frame width\n",
    "    height = np.size(img, 0) # get face frame height\n",
    "    for (x, y, w, h) in eyes:\n",
    "        if y > height / 2:\n",
    "            pass\n",
    "        eyecenter = x + w / 2  # get the eye center\n",
    "        if eyecenter < width * 0.5:\n",
    "            left_eye = img[y:y + h, x:x + w]\n",
    "        else:\n",
    "            right_eye = img[y:y + h, x:x + w]\n",
    "    return left_eye, right_eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c539c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(img, classifier):\n",
    "    gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    coords = face_cascade.detectMultiScale(gray_frame, 1.3, 5)\n",
    "    if len(coords) > 1:\n",
    "        biggest = (0, 0, 0, 0)\n",
    "        for i in coords:\n",
    "            if i[3] > biggest[3]:\n",
    "                biggest = i\n",
    "        biggest = np.array([i], np.int32)\n",
    "    elif len(coords) == 1:\n",
    "        biggest = coords\n",
    "    else:\n",
    "        return None\n",
    "    for (x, y, w, h) in biggest:\n",
    "        frame = img[y:y + h, x:x + w]\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e145d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_params = cv2.SimpleBlobDetector_Params()\n",
    "detector_params.filterByArea = True\n",
    "detector_params.maxArea = 1500\n",
    "detector = cv2.SimpleBlobDetector_create(detector_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "791c0638",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaf2bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_eyebrows(img):\n",
    "    height, width = img.shape[:2]\n",
    "    eyebrow_h = int(height / 4)\n",
    "    img = img[eyebrow_h:height, 0:width]  # cut eyebrows out (15 px)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "352531d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eye' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m     keypoints \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39mdetect(img)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m keypoints\n\u001b[1;32m----> 6\u001b[0m keypoints \u001b[38;5;241m=\u001b[39m blob_process(\u001b[43meye\u001b[49m, detector)\n\u001b[0;32m      7\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdrawKeypoints(eye, keypoints, eye, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mDRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eye' is not defined"
     ]
    }
   ],
   "source": [
    "def blob_process(img, detector):\n",
    "    gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, img = cv2.threshold(gray_frame, 42, 255, cv2.THRESH_BINARY)\n",
    "    keypoints = detector.detect(img)\n",
    "    return keypoints\n",
    "keypoints = blob_process(eye, detector)\n",
    "cv2.drawKeypoints(eye, keypoints, eye, (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e4e5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Baseline set at: 19.50\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n",
      "↓ Scroll Down\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import time\n",
    "\n",
    "# Load cascades\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade  = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "if face_cascade.empty() or eye_cascade.empty():\n",
    "    print(\"Error loading cascade files.\")\n",
    "    exit()\n",
    "\n",
    "# Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot access camera.\")\n",
    "    exit()\n",
    "\n",
    "scroll_cooldown = 1.0  # seconds\n",
    "last_scroll_time = time.time()\n",
    "\n",
    "# Threshold to consider eye closed\n",
    "INTENSITY_THRESHOLD = 60\n",
    "\n",
    "def is_eye_closed(eye_gray):\n",
    "    # Get average brightness of eye region\n",
    "    brightness = np.mean(eye_gray)\n",
    "    return brightness < INTENSITY_THRESHOLD\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray  = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_gray  = gray[y:y+h, x:x+w]\n",
    "        face_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        eyes = eye_cascade.detectMultiScale(face_gray, 1.3, 5)\n",
    "        eyes = sorted(eyes, key=lambda e: e[0])  # Sort by x to get left/right order\n",
    "\n",
    "        if len(eyes) >= 2:\n",
    "            (lx, ly, lw, lh) = eyes[0]  # Left eye\n",
    "            (rx, ry, rw, rh) = eyes[1]  # Right eye\n",
    "\n",
    "            left_eye  = face_gray[ly:ly+lh, lx:lx+lw]\n",
    "            right_eye = face_gray[ry:ry+rh, rx:rx+rw]\n",
    "\n",
    "            now = time.time()\n",
    "\n",
    "            if is_eye_closed(left_eye) and not is_eye_closed(right_eye):\n",
    "                if now - last_scroll_time > scroll_cooldown:\n",
    "                    pyautogui.scroll(-150)  # Scroll down\n",
    "                    print(\"↓ Left eye closed → Scroll down\")\n",
    "                    last_scroll_time = now\n",
    "\n",
    "            elif is_eye_closed(right_eye) and not is_eye_closed(left_eye):\n",
    "                if now - last_scroll_time > scroll_cooldown:\n",
    "                    pyautogui.scroll(150)  # Scroll up\n",
    "                    print(\"↑ Right eye closed → Scroll up\")\n",
    "                    last_scroll_time = now\n",
    "\n",
    "            # Optional: visualize eyes\n",
    "            cv2.rectangle(face_color, (lx, ly), (lx+lw, ly+lh), (255, 0, 0), 2)\n",
    "            cv2.rectangle(face_color, (rx, ry), (rx+rw, ry+rh), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Eye Blink Scroll\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84234dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
